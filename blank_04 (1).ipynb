{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u49LZV9dKFWi"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-735c84f5bda7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# %%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m mnist_train = datasets.FashionMNIST('./fashion_mnist/train', train=True,\n\u001b[0m\u001b[0;32m      8\u001b[0m                                     transform=transforms.Compose([transforms.ToTensor()]))\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# %%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dataset not found. You can use download=True to download it\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# %%\n",
    "mnist_train = datasets.FashionMNIST('./fashion_mnist/train', train=True,\n",
    "                                    transform=transforms.Compose([transforms.ToTensor()]))\n",
    "# %%\n",
    "mnist_test = datasets.FashionMNIST('./fashion_mnist/test', train=False,\n",
    "                                   transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "mnist_train.data = mnist_train.data.float()\n",
    "# %%\n",
    "device = 'cpu'  # 'mps' if torch.has_mps else 'cpu'\n",
    "# %%\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(28 * 28, 2048),\n",
    "    torch.nn.LeakyReLU(0.05),\n",
    "    torch.nn.Linear(2048, 32),\n",
    "    torch.nn.LeakyReLU(2),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(32, len(mnist_train.classes))\n",
    ").to(device)\n",
    "\n",
    "\n",
    "def test_accuracy(_model, _test_loader, _loss_func) -> [float, float]:\n",
    "    \"\"\" Возвращает два числа -- точность и лосс \"\"\"\n",
    "    acc = 0\n",
    "    _loss = 0\n",
    "    with torch.no_grad():\n",
    "        for j, (x, y) in enumerate(_test_loader, 1):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(x)\n",
    "            acc += torch.sum(torch.eq(pred.argmax(dim=1).long().to('cpu'), y.to('cpu')))\n",
    "            _loss += _loss_func(pred, y)\n",
    "\n",
    "    return acc / _test_loader.dataset.data.shape[0], _loss / j\n",
    "\n",
    "\n",
    "# %%\n",
    "def train(_model, train_data, test_data, epochs: int = 30, batch_size: int = 20_000) -> [torch.nn.Module, pd.DataFrame]:\n",
    "    optimizer = torch.optim.Adam(_model.parameters(), weight_decay=0.00001)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "    log = pd.DataFrame(columns=['epoch', 'train_loss', 'test_accuracy', 'test_loss'])\n",
    "\n",
    "    for i in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for j, (x, y) in enumerate(loader, 1):\n",
    "            x = x.data.to(device)\n",
    "            y = y.data.to(device)\n",
    "            y_pred = _model(x.data)\n",
    "            running_loss = loss(y_pred, y)\n",
    "            running_loss.backward()\n",
    "\n",
    "            epoch_loss += running_loss.item()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        test_acc, test_loss = test_accuracy(model, test_loader, loss)\n",
    "        log.loc[i] = [i + 1, epoch_loss / j, test_acc.item(), test_loss.item()]\n",
    "\n",
    "        print(f'EPOCH: {i + 1 :3d}  |  LOSS: {epoch_loss / j: .4f}', end='  |  ')\n",
    "        print(f'TEST LOSS: {test_loss:0.4f}  |  TEST ACCURACY: {test_acc:0.4f}')\n",
    "\n",
    "    return _model, log\n",
    "\n",
    "\n",
    "# %%\n",
    "model, log = train(model, mnist_train, mnist_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "403Mis3LAgED"
   },
   "source": [
    "## 1. Классификация предметов одежды (датасет Fashion MNIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mn6r8tMDQsaU"
   },
   "source": [
    "\n",
    "### 1.1 Решить задачу классификации, не используя сверточные слои. \n",
    "* Предложить архитектуру модели для решения задачи\n",
    "* Посчитать количество параметров модели.\n",
    "* Обучить модель\n",
    "* Вывести график функции потерь по эпохам. \n",
    "* Используя тестовое множество\n",
    "\n",
    "  * Продемонстрировать работу модели: вывести несколько изображений, указать над ними правильный класс и класс, предсказанный моделью. \n",
    "\n",
    "  * Вывести матрицу ошибок.\n",
    "\n",
    "  * Вывести значение accuracy на тестовом множестве.\n",
    "* Сохранить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9c5bc723d984>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m mnist_train = datasets.FashionMNIST('./fashion_mnist/train', train=True,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                     transform=transforms.Compose([transforms.ToTensor()]))\n\u001b[0;32m      3\u001b[0m \u001b[0mmnist_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dataset not found. You can use download=True to download it\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "mnist_train = datasets.FashionMNIST('./fashion_mnist/train', train=True,\n",
    "                                    transform=transforms.Compose([transforms.ToTensor()]))\n",
    "mnist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = datasets.FashionMNIST('./fashion_mnist/test', train=False,\n",
    "                                   transform=transforms.Compose([transforms.ToTensor()]))\n",
    "mnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'  #  'mps' if torch.has_mps else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(28 * 28, 2048),\n",
    "    torch.nn.LeakyReLU(0.05),\n",
    "    torch.nn.Linear(2048, 32),\n",
    "    torch.nn.LeakyReLU(2),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(32, len(mnist_train.classes))\n",
    ").to(device)\n",
    "\n",
    "number_params = 0\n",
    "for param in model.parameters():\n",
    "    number_params += torch.prod(torch.tensor(param.shape))\n",
    "\n",
    "number_params  # Количество параметров в сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(_model, _test_loader, _loss_func) -> [float, float]:\n",
    "    \"\"\" Возвращает два числа -- точность и лосс \"\"\"\n",
    "    acc = 0\n",
    "    _loss = 0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for j, (_x, _y) in enumerate(_test_loader, 1):\n",
    "            _x = _x.to(device)\n",
    "            _y = _y.to(device)\n",
    "            pred = model(_x)\n",
    "            acc += torch.sum(torch.eq(pred.argmax(dim=1).long(), _y))\n",
    "            n += pred.shape[0]\n",
    "            _loss += _loss_func(pred, _y)\n",
    "\n",
    "    return acc / n, _loss / j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(_model, train_data, test_data, epochs: int = 30, batch_size: int = 20_000) -> [torch.nn.Module, pd.DataFrame]:\n",
    "    optimizer = torch.optim.Adam(_model.parameters(), weight_decay=0.0001)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers=8)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "    _log = pd.DataFrame(columns=['epoch', 'train_loss', 'test_accuracy', 'test_loss'])\n",
    "\n",
    "    for i in range(epochs + 1):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        j = 1\n",
    "        if i > 0:\n",
    "            for j, (_x, _y) in enumerate(loader, 1):\n",
    "                _x = _x.data.to(device)\n",
    "                _y = _y.data.to(device)\n",
    "                y_pred = _model(_x.data)\n",
    "                running_loss = loss(y_pred, _y)\n",
    "                running_loss.backward()\n",
    "\n",
    "                epoch_loss += running_loss.item()\n",
    "\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        test_acc, test_loss = test_accuracy(model, test_loader, loss)\n",
    "        _log.loc[i] = [i, epoch_loss / j, test_acc.item(), test_loss.item()]\n",
    "\n",
    "        print(f'EPOCH: {i :3d}  |  LOSS: {epoch_loss / j: .4f}', end='  |  ')\n",
    "        print(f'TEST LOSS: {test_loss:0.4f}  |  TEST ACCURACY: {test_acc:0.4f}')\n",
    "\n",
    "    return _model, _log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, log = train(model, mnist_train, mnist_test, 3, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(log, x='epoch', y=['train_loss', 'test_loss'], title='<b>LOSS PLOT</b>').show(renderer='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(log, x='epoch', y='test_accuracy', title='<b>TEST ACCURACY</b>').show(renderer='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model.to('cpu')\n",
    "right_ans = torch.zeros(mnist_test.data.shape[0]).to('cpu')\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for x, _ in DataLoader(mnist_test, batch_size=2000):\n",
    "        x = x.to('cpu')\n",
    "        right_ans[i:i + x.shape[0]] += model(x).argmax(dim=1)\n",
    "        i += x.shape[0]\n",
    "\n",
    "cm = confusion_matrix(mnist_test.targets.numpy(), right_ans.long().numpy())\n",
    "px.imshow(cm).show(renderer='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/mnist_linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "for i in np.random.randint(0, mnist_test.targets.shape[0], 3):\n",
    "    id_class = mnist_test.targets[i]\n",
    "    class_name = mnist_test.classes[id_class]\n",
    "\n",
    "    id_predicted = model(mnist_test.data[i:i + 1].float()).argmax(dim=1).item()\n",
    "    class_name_predicted = mnist_test.classes[id_predicted]\n",
    "    print(f'CLASS : {id_class} ({class_name})  |  '\n",
    "          f'PREDICTED CLASS : {id_predicted} ({class_name_predicted})')\n",
    "    px.imshow(mnist_test.data[i], color_continuous_scale='gray').show(renderer='png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmsMQUPP-XUh"
   },
   "source": [
    "### 1.2 Решить задачу 1.1, используя сверточную нейронную сеть. \n",
    "* Добиться значения accuracy на тестовом множестве не менее 90%\n",
    "* Визуализировать результаты работы первого сверточного слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.FashionMNIST('./fashion_mnist/train', train=True,\n",
    "                                    transform=transforms.Compose([transforms.ToTensor()]))\n",
    "mnist_test = datasets.FashionMNIST('./fashion_mnist/test', train=False,\n",
    "                                   transform=transforms.Compose([transforms.ToTensor()]))\n",
    "mnist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.2\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "\n",
    "    torch.nn.BatchNorm2d(1),\n",
    "\n",
    "    torch.nn.Conv2d(1, 8, (3, 3), padding=1),\n",
    "    torch.nn.BatchNorm2d(8),\n",
    "    torch.nn.ReLU(),\n",
    "\n",
    "    torch.nn.Conv2d(8, 64, (3, 3), padding=1),\n",
    "    torch.nn.MaxPool2d((2, 2)),\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.ReLU(),\n",
    "\n",
    "    torch.nn.Dropout(p),\n",
    "\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(12544, 2048),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(2048, 10)\n",
    "\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_params = 0\n",
    "for param in model.parameters():\n",
    "    number_params += torch.prod(torch.tensor(param.shape))\n",
    "\n",
    "number_params  # Количество параметров в сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, log = train(model, mnist_train, mnist_test, 3, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "np.random.seed(21)\n",
    "\n",
    "pic, target = next(iter(DataLoader(mnist_test, batch_size=1)))\n",
    "fst_pic = model[:2](pic)[0]\n",
    "\n",
    "print(f'CLASS : {target} ({mnist_test.classes[target]})')\n",
    "for pic_i in fst_pic:\n",
    "    fig = make_subplots(1, 2)\n",
    "    px.imshow(pic_i.detach().numpy(), color_continuous_scale='gray').show(renderer='png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cm6_9B3ZKLq9"
   },
   "source": [
    "##  2. Классификация изображений (датасет CIFAR 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNTZa9yWQvSF"
   },
   "source": [
    "\n",
    "### 2.1 Решить задачу классификации, не используя сверточные слои. \n",
    "\n",
    "* Нормализовать данные (если необходимо)\n",
    "* Предложить архитектуру модели для решения задачи\n",
    "* Посчитать количество параметров модели.\n",
    "* Обучить модель\n",
    "* Вывести график функции потерь по эпохам. \n",
    "* Используя тестовое множество\n",
    "\n",
    "  * Продемонстрировать работу модели: вывести несколько изображений, указать над ними правильный класс и класс, предсказанный моделью. \n",
    "\n",
    "  * Вывести матрицу ошибок.\n",
    "\n",
    "  * Вывести значение accuracy на тестовом множестве.\n",
    "* Сохранить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorReshape:\n",
    "    def __call__(self, _x):\n",
    "        return _x.reshape(3, 32, 32)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'TensorReshape()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train = datasets.CIFAR10('./cifar_mnist/train', train=True, download=False,\n",
    "                               transform=transforms.Compose([transforms.ToTensor(), TensorReshape()]))\n",
    "\n",
    "cifar_test = datasets.CIFAR10('./cifar_mnist/train', train=False, download=False,\n",
    "                              transform=transforms.Compose([transforms.ToTensor(), TensorReshape()]))\n",
    "cifar_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.BatchNorm2d(3),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(3 * 32 * 32, 2048),\n",
    "    torch.nn.LeakyReLU(0.05),\n",
    "    torch.nn.Linear(2048, 32),\n",
    "    torch.nn.LeakyReLU(2),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(32, len(cifar_train.classes))\n",
    ").to(device)\n",
    "\n",
    "number_params = 0\n",
    "for param in model.parameters():\n",
    "    number_params += torch.prod(torch.tensor(param.shape))\n",
    "\n",
    "number_params  # Количество параметров в сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, log = train(model, cifar_train, cifar_test, epochs=2, batch_size=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.line(log, x='epoch', y=['train_loss', 'test_loss'], title='<b>LOSS PLOT</b>').show(renderer='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(log, x='epoch', y='test_accuracy', title='<b>TEST ACCURACY</b>').show(renderer='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "model.to('cpu')\n",
    "right_ans = torch.zeros(cifar_test.data.shape[0]).to('cpu')\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for x, _ in DataLoader(cifar_test, batch_size=2000):\n",
    "        x = x.to('cpu')\n",
    "        right_ans[i:i + x.shape[0]] += model(x).argmax(dim=1)\n",
    "        i += x.shape[0]\n",
    "\n",
    "cm = confusion_matrix(cifar_test.targets, right_ans.long().numpy())\n",
    "px.imshow(cm).show(renderer='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/cifar_linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "model.eval()\n",
    "for i in np.random.randint(0, cifar_test.targets.__len__(), 3):\n",
    "    id_class = cifar_test.targets[i]\n",
    "    class_name = cifar_test.classes[id_class]\n",
    "    image = torch.tensor(cifar_test.data[i:i + 1]).float().reshape(1, 3, 32, 32)\n",
    "\n",
    "    id_predicted = model(image).argmax(axis=1).item()\n",
    "    class_name_predicted = cifar_test.classes[id_predicted]\n",
    "    print(f'CLASS : {id_class} ({class_name})  |  '\n",
    "          f'PREDICTED CLASS : {id_predicted} ({class_name_predicted})')\n",
    "    px.imshow(cifar_test.data[i], color_continuous_scale='gray').show(renderer='png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIxHLbKcDCFA"
   },
   "source": [
    "### 2.2 Решить задачу 2.1, используя сверточную нейронную сеть. \n",
    "* Добиться значения accuracy на тестовом множестве не менее 70%.\n",
    "* Визуализировать результаты работы первого сверточного слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "\n",
    "    torch.nn.BatchNorm2d(3),\n",
    "    torch.nn.Conv2d(3, 16, (3, 3), padding=1),\n",
    "    torch.nn.MaxPool2d((2, 2)),\n",
    "    torch.nn.ReLU(),\n",
    "\n",
    "    torch.nn.BatchNorm2d(16),\n",
    "    torch.nn.Conv2d(16, 64, (3, 3), padding=1),\n",
    "    torch.nn.MaxPool2d((2, 2)),\n",
    "    torch.nn.ReLU(),\n",
    "\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.Conv2d(64, 64, (3, 3), padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.Conv2d(64, 128, (3, 3), padding=1),\n",
    "    torch.nn.MaxPool2d((2, 2)),\n",
    "    torch.nn.ReLU(),\n",
    "\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(16 * 128, len(cifar_train.classes))\n",
    ").to(device)\n",
    "\n",
    "number_params = 0\n",
    "for param in model.parameters():\n",
    "    number_params += torch.prod(torch.tensor(param.shape))\n",
    "\n",
    "number_params  # Количество параметров в сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, log = train(model, cifar_train, cifar_test, epochs=3, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=4, cols=4)\n",
    "\n",
    "images = model[:2](torch.tensor(cifar_test.data[20:21].reshape(1, 3, 32, 32)).float()).reshape(16, 32,\n",
    "                                                                                               32).detach().numpy()\n",
    "\n",
    "for n, image in enumerate(images):\n",
    "    fig.add_trace(px.imshow(image).data[0], row=n // 4 + 1, col=n % 4 + 1)\n",
    "\n",
    "layout = px.imshow(images[0], color_continuous_scale='gray').layout\n",
    "fig.layout.coloraxis = layout.coloraxis\n",
    "# fig.update_xaxes(**layout.xaxis.to_plotly_json())\n",
    "# fig.update_yaxes(**layout.yaxis.to_plotly_json())\n",
    "fig.show(autoscale=False, height=1000, width=1000, renderer='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(cifar_test.data[20:21].reshape(32, 32, 3)).show(renderer='png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPg8k4YTFOgc"
   },
   "source": [
    "## 3. Загрузка изображений из внешних источников"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hLnpe_570wd"
   },
   "source": [
    "### 3.1 Решить задачу классификации обезьян (датасет [monkey.zip](https://disk.yandex.ru/d/OxYgY4S7aR6ulQ)).\n",
    "* Загрузить архив с данными на диск\n",
    "* Создать датасет на основе файлов при помощи `torchvision.datasets.ImageFolder`\n",
    "* Преобразовать изображения к тензорами одного размера (например, 400х400). Потестировать другие преобразования из `torchvision.transforms`\n",
    "* Предложить архитектуру модели для решения задачи. Обучить модель.\n",
    "* Используя тестовое множество\n",
    "\n",
    "  * Продемонстрировать работу модели: вывести несколько изображений, указать над ними правильный класс и класс, предсказанный моделью. \n",
    "\n",
    "  * Вывести матрицу ошибок.\n",
    "\n",
    "  * Вывести значение accuracy на тестовом множестве.\n",
    "  * Добиться значения accuracy на тестовом множестве не менее 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1616695933807,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "iXnzblkFFN5K",
    "outputId": "cbbabfdc-a8c4-41c6-86a8-f7e99748a612"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17268,
     "status": "ok",
     "timestamp": 1616695954172,
     "user": {
      "displayName": "Никита Блохин",
      "photoUrl": "",
      "userId": "16402972581398673009"
     },
     "user_tz": -180
    },
    "id": "4Er_FLV6Hrqq",
    "outputId": "5ece4316-16e6-458c-eb94-c0604e19ea24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1371/1371 [00:16<00:00, 81.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "zf = zipfile.ZipFile('drive/MyDrive/datasets/monkeys.zip')\n",
    "for file in tqdm(zf.infolist()):\n",
    "    zf.extract(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-tMy4qJ9j1k"
   },
   "source": [
    "### 3.2 Решить задачу классификации собак и кошек (датасет [cats_dogs.zip](https://disk.yandex.ru/d/wQtt5O1JF9ctnA)).\n",
    "* Загрузить архив с данными на диск\n",
    "* Создать датасет на основе файлов при помощи `torchvision.datasets.ImageFolder`\n",
    "* Преобразовать изображения к тензорами одного размера (например, 400х400). Потестировать другие преобразования из `torchvision.transforms`\n",
    "* Предложить архитектуру модели для решения задачи. Обучить модель.\n",
    "* Используя тестовое множество\n",
    "\n",
    "  * Продемонстрировать работу модели: вывести несколько изображений, указать над ними правильный класс и класс, предсказанный моделью. \n",
    "\n",
    "  * Вывести матрицу ошибок.\n",
    "\n",
    "  * Вывести значение accuracy на тестовом множестве.\n",
    "  * Добиться значения accuracy на тестовом множестве не менее 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqvleAgxfC6B"
   },
   "source": [
    "# 4. Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjNUwuho9tm9"
   },
   "source": [
    "### 4.1 Решить задачу 3.1, воспользовавшись предобученной моделью VGG16\n",
    "* Загрузить данные для обучения\n",
    "* Преобразования: размер 224x224, нормализация с параметрами `mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)`\n",
    "* Заменить последний полносвязный слой модели в соответствии с задачей\n",
    "* Дообучить модель (не замораживать веса). Вычислить значение accuracy на тестовом множестве\n",
    "* Дообучить модель (заморозить все веса, кроме последнего блока слоев (`classifier`)). \n",
    "* Вычислить значение accuracy на тестовом множестве.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt_hXy5a5CE8"
   },
   "source": [
    "### 4.2 Решить задачу 3.2, воспользовавшись подходящей предобученной моделью\n",
    "* Не использовать VGG16 (вместо нее можно взять resnet18 или другую)\n",
    "* Загрузить данные для обучения\n",
    "* Преобразования: размер 224x224, нормализация с параметрами `mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)`\n",
    "* Заменить последний полносвязный слой модели в соответствии с задачей\n",
    "* Дообучить модель. \n",
    "* Вычислить значение accuracy на тестовом множестве (добиться значения не меньше 97-98%)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMF+zO/4VvRSXLWjIV8BHI2",
   "collapsed_sections": [],
   "name": "blank_04_cnn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
